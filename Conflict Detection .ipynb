{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8451abff",
   "metadata": {},
   "source": [
    "# 1 TWITTER API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb061ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import webbrowser\n",
    "import time\n",
    "import re\n",
    "from myconfig import *\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import download\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b291fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter class for fetching tweets\n",
    "\n",
    "class TwitterClient(object):\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self.auth = tweepy.OAuthHandler(twitterApiKey,twitterApiKeySecret)\n",
    "            self.auth.set_access_token(twitterAccessToken,twitterAccessTokenSecret)\n",
    "            self.api = tweepy.API(self.auth)\n",
    "            assert self.api\n",
    "        except:\n",
    "            print(\"Error: Authentication Failed\")\n",
    "    \n",
    "    def clean_tweet(self, tweet):\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "    \n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        # create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "    \n",
    "    def get_tweets(self, query, count = 10):\n",
    "        tweets = []\n",
    "        try:\n",
    "            fetched_tweets = self.api.search_tweets(q = query, count = count)\n",
    "            for tweet in fetched_tweets:\n",
    "                all_english = True\n",
    "                for c in tweet['text']:\n",
    "                    if ord(c) >= 256:\n",
    "                        all_english = False\n",
    "                        break\n",
    "                if not all_english:\n",
    "                    continue\n",
    "                parsed_tweet = {}\n",
    "                parsed_tweet['text'] = tweet.text\n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
    "                if tweet.retweet_count > 0:\n",
    "                    if parsed_tweet not in tweets:\n",
    "                        tweets.append(parsed_tweet)\n",
    "                else:\n",
    "                    tweets.append(parsed_tweet)\n",
    "            return tweets\n",
    "        except tweepy.TweepyException as e:\n",
    "            print(\"Error : \" + str(e))\n",
    "\n",
    "    def fetch_tweets(self, query, count = 10):\n",
    "        try:\n",
    "            return self.api.search_tweets(q = query, count = count)\n",
    "        except tweepy.TweepyException as e:\n",
    "            print(\"Error : \" + str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553c6347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Authentication Failed\n"
     ]
    }
   ],
   "source": [
    "tc = TwitterClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b03f01ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TwitterClient' object has no attribute 'api'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fe7bc560f478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tweets.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#Modi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_$_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a0503600073a>\u001b[0m in \u001b[0;36mfetch_tweets\u001b[0;34m(self, query, count)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTweepyException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TwitterClient' object has no attribute 'api'"
     ]
    }
   ],
   "source": [
    "with open('tweets.txt','w') as f:\n",
    "    tweets = tc.fetch_tweets('#Modi',100)\n",
    "    for tweet in tweets:\n",
    "        f.write(tweet.text+\"_$_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652de60",
   "metadata": {},
   "source": [
    "# 2 Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dbd8e2",
   "metadata": {},
   "source": [
    "# 2.1 Reading Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5540a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'தேர்தல் சமயத்தில்தான் பாஜக கங்கையில் நீராடும்; தொற்றால் மக்கள் உயிரிழந்தபோது அதே கங்கையில் சடலங்களை தூக்கி எறிவார்க… https://t.co/yz7rKy7kB8'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('tweets.txt', 'r')\n",
    "tweets = f.read().split('_$_')\n",
    "f.close()\n",
    "tweets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7778b9df",
   "metadata": {},
   "source": [
    "# 2.2 Pre-processing each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52b1c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    '''\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    '''\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "            word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    # removing non-english words (words of other languages likes Hindi etc)\n",
    "    tweets_eng = []\n",
    "    for word in tweets_clean:\n",
    "        flag = True\n",
    "        for i in word:\n",
    "            # letter > 256 => non-english letter => remove word\n",
    "            if ord(i) >= 256:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            tweets_eng.append(word)\n",
    "    return tweets_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727b1536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "தேர்தல் சமயத்தில்தான் பாஜக கங்கையில் நீராடும்; தொற்றால் மக்கள் உயிரிழந்தபோது அதே கங்கையில் சடலங்களை தூக்கி எறிவார்க… https://t.co/yz7rKy7kB8\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "processed_tweets = [process_tweet(tweet) for tweet in tweets]\n",
    "print(tweets[0])\n",
    "print(processed_tweets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3225b1bb",
   "metadata": {},
   "source": [
    "# 3 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6515ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(tweet:list, freqs:dict, wordToTweet:dict):\n",
    "    for word in tweet:\n",
    "        if word in freqs:\n",
    "            freqs[word] += 1\n",
    "            wordToTweet[word].append(tweet)\n",
    "        else:\n",
    "            freqs[word] = 1\n",
    "            wordToTweet[word] = [tweet]\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e422fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = dict()\n",
    "wordToTweet = dict()\n",
    "for tweet in processed_tweets:\n",
    "    count_words(tweet, freqs, wordToTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08fd5699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(freqs.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce8e65",
   "metadata": {},
   "source": [
    "# 4 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03712947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freqs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c5b9eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ekadashi', 63)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_word = np.argmax(list(freqs.values()))\n",
    "list(freqs.items())[most_freq_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd56753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ekadashi', 63),\n",
       " ('modi', 49),\n",
       " ('shukla', 42),\n",
       " ('paksha', 42),\n",
       " ('day', 23),\n",
       " ('11', 22),\n",
       " ('1/3', 21),\n",
       " ('today', 21),\n",
       " ('guruvayoor', 21),\n",
       " ('vrishikam', 21)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Sorted in descending order of frequencies\n",
    "freq_sorted = list(freqs.items())\n",
    "freq_sorted.sort(key = lambda x : -x[1])\n",
    "freq_sorted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1bfec5",
   "metadata": {},
   "source": [
    "# 5 Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87549e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tweet, alphabet):\n",
    "    v = np.zeros(len(alphabet))\n",
    "    for i in range(len(alphabet)):\n",
    "        if alphabet[i] in tweet:\n",
    "            v[i] += 1\n",
    "    return v\n",
    "\n",
    "def normalize(v):\n",
    "    norm = np.power(np.sum(np.power(v,2)), 0.5)\n",
    "    if norm == 0:\n",
    "        return 0\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b8a4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def len_counts(clusters):\n",
    "    lens = [len(cluster) for cluster in clusters.values()]\n",
    "    return dict(Counter(lens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba48952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_dist(clusterA, clusterB, vectors):\n",
    "    dist_sum = 0\n",
    "    for i in clusterA:\n",
    "        for j in clusterB:\n",
    "            dist_sum += np.sum(np.power(vectors[i] - vectors[j], 2))\n",
    "    \n",
    "    dist_avg = dist_sum / (len(clusterA) * len(clusterB))\n",
    "    return dist_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9d153e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeOnce(clusters, vectors):\n",
    "    min_dist = 2**30\n",
    "    min_loc = (0, 0)\n",
    "    for clusterInxA in clusters:\n",
    "        for clusterInxB in clusters:\n",
    "            if clusterInxA != clusterInxB:\n",
    "                dist = get_avg_dist(clusters[clusterInxA], clusters[clusterInxB], vectors)\n",
    "                if dist < min_dist:\n",
    "                    min_loc = (clusterInxA, clusterInxB)\n",
    "                    min_dist = dist\n",
    "\n",
    "    clusters[min_loc[0]] = clusters[min_loc[0]] + clusters[min_loc[1]]\n",
    "    clusters.pop(min_loc[1])\n",
    "\n",
    "def mergeToK(clusters, vectors, K):\n",
    "    while len(clusters.keys()) > K:\n",
    "        mergeOnce(clusters, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d64ed606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_unique_tweets(tweets, cluster):\n",
    "    c_tweets = [tweets[i] for i in cluster]\n",
    "    for i in range(len(c_tweets)):\n",
    "        if not c_tweets[i] in c_tweets[:i]:\n",
    "            print(c_tweets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "954e4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = [i[0] for i in freq_sorted]\n",
    "n = len(processed_tweets)\n",
    "m = len(alphabet)\n",
    "clusters = dict()\n",
    "vectors = dict()\n",
    "for i in range(n):\n",
    "    vectors[i] = vectorize(processed_tweets[i], alphabet)\n",
    "    clusters[i] = [i]\n",
    "mergeToK(clusters, vectors, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6607bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths:\n",
      "{0: 66, 20: 21, 28: 1, 32: 1, 34: 1, 44: 1, 50: 1, 60: 1, 62: 2, 75: 1, 79: 1, 82: 1, 87: 1, 89: 1, 90: 1}\n",
      "len counts:\n",
      "{66: 1, 21: 1, 1: 12, 2: 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"lengths:\")\n",
    "print({cluster:len(clusters[cluster]) for cluster in clusters})\n",
    "print(\"len counts:\")\n",
    "print(len_counts(clusters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0267524",
   "metadata": {},
   "source": [
    "# Classification of Tweets into Positive or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5e1e24",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TwitterClient' object has no attribute 'api'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b9df24db3282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ssr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# picking positive tweets from tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mptweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# percentage of positive tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Positive tweets percentage: {} %\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a0503600073a>\u001b[0m in \u001b[0;36mget_tweets\u001b[0;34m(self, query, count)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mfetched_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetched_tweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mall_english\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TwitterClient' object has no attribute 'api'"
     ]
    }
   ],
   "source": [
    "tweets = tc.get_tweets(query = 'ssr', count = 10000)\n",
    "# picking positive tweets from tweets\n",
    "ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "# percentage of positive tweets\n",
    "print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets)))\n",
    "# picking negative tweets from tweets\n",
    "ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "# picking neutral tweets from tweets\n",
    "\n",
    "neutweets = [tweet for tweet in tweets if tweet['sentiment'] == 'neutral']\n",
    "\n",
    "# percentage of negative tweets\n",
    "print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets)))\n",
    "# percentage of neutral tweets\n",
    "print(\"Neutral tweets percentage: {} % \\\n",
    "    \".format(100*(len(tweets) -(len( ntweets )+len( ptweets)))/len(tweets)))\n",
    "# printing first 5 positive tweets\n",
    "print(\"\\n\\nPositive tweets:\")\n",
    "for tweet in ptweets[:10]:\n",
    "    print(tweet['text'])\n",
    "  \n",
    " # printing first 5 negative tweets\n",
    "print(\"\\n\\nNegative tweets:\")\n",
    "for tweet in ntweets[:10]:\n",
    "    print(tweet['text'])\n",
    "    \n",
    "# printing first 5 neutral tweets\n",
    "print(\"\\n\\nNeutral tweets:\")\n",
    "for tweet in neutweets[:10]:\n",
    "    print(tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3d4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4748d34e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
