{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handy-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tweepy\n",
    "import numpy as np\n",
    "from tweepy import OAuthHandler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8de553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ./auth.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "departmental-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient(object):\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self.auth = OAuthHandler(os.getenv('consumer_key'), os.getenv('consumer_secret'))\n",
    "            self.auth.set_access_token(os.getenv('access_token'), os.getenv('access_token_secret'))\n",
    "            self.api = tweepy.API(self.auth)\n",
    "        except Tweepy.TweepError:\n",
    "            print(\"Error: Authentication Failed\")\n",
    "\n",
    "    def get_tweets(self, query, count = 10):\n",
    "        tweets = []\n",
    "        try:\n",
    "            fetched_tweets = self.api.search_tweets(q = query, count = count)\n",
    "            for tweet in fetched_tweets:\n",
    "                if tweet.text not in tweets:\n",
    "                    tweets.append(tweet.text)\n",
    "            return tweets\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Error : \" + str(e))\n",
    "            \n",
    "    def get_trending_tags(self):\n",
    "        trends1 = self.api.get_place_trends(1)\n",
    "        data = trends1[0] \n",
    "        trends = data['trends']\n",
    "        names = []\n",
    "        for trend in trends:\n",
    "            if trend['name'][0]=='#':\n",
    "                names.append(trend['name'])\n",
    "        return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attended-seventh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#UFC269',\n",
       " '#RedBullBatalla',\n",
       " '#それスノ',\n",
       " '#FinalBattle',\n",
       " '#HBDSuperstarRajinikanth']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = TwitterClient()\n",
    "# api.get_tweets(query = '#chess', count = 200)\n",
    "api.get_trending_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stock-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.txt', 'w') as f:\n",
    "    tweets = api.get_tweets('#Rhea', 20000)\n",
    "    for tweet in tweets:\n",
    "        f.write(tweet + \"_$_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e51c00",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7f59b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data.txt', 'r')\n",
    "tweets = f.read().split('_$_')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae7da8d",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fbcb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import download\n",
    "# download('stopwords')\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    '''\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    '''\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "            word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    tweets_eng = []\n",
    "    for word in tweets_clean:\n",
    "        flag = True\n",
    "        for i in word:\n",
    "            if ord(i) >= 256:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            tweets_eng.append(word)\n",
    "    return tweets_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05fd7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets = [process_tweet(tweet) for tweet in tweets]\n",
    "while [] in processed_tweets:\n",
    "    processed_tweets.remove([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "637797be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bceb7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(tweet:list, freqs:dict, wordToTweet:dict):\n",
    "    for word in tweet:\n",
    "        if word in freqs:\n",
    "            freqs[word] += 1\n",
    "            wordToTweet[word].append(tweet)\n",
    "        else:\n",
    "            freqs[word] = 1\n",
    "            wordToTweet[word] = [tweet]\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65f75071",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = dict()\n",
    "wordToTweet = dict()\n",
    "for tweet in processed_tweets:\n",
    "    count_words(tweet, freqs, wordToTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e23828b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'holdssrculpritsaccount': 1,\n",
       " 'kill': 1,\n",
       " 'sushantsinghrajput': 4,\n",
       " 'role': 1,\n",
       " 'rhea': 50,\n",
       " 'salmankhan': 1,\n",
       " 'surajpancholi': 1,\n",
       " 'via': 1,\n",
       " 'telepath': 1,\n",
       " 'link': 1,\n",
       " 'zhiao': 2,\n",
       " 'know': 3,\n",
       " 'think': 1,\n",
       " 'hehe': 1,\n",
       " 'queso': 1,\n",
       " 'cummi': 1,\n",
       " '...': 9,\n",
       " 'nooo': 1,\n",
       " 'beagl': 1,\n",
       " 'run': 1,\n",
       " 'part': 1,\n",
       " '4': 2,\n",
       " 'seteth': 5,\n",
       " 'neat': 1,\n",
       " 'byleth': 2,\n",
       " 'setleth': 1,\n",
       " 'rhealeth': 1,\n",
       " 'fe3h': 16,\n",
       " 'fireemblemthreehous': 7,\n",
       " 'eunjeong': 1,\n",
       " 'heymama': 1,\n",
       " 'cover': 1,\n",
       " 'children': 1,\n",
       " 'goddess': 1,\n",
       " 'go': 3,\n",
       " 'trick': 1,\n",
       " 'treat': 1,\n",
       " 'fehero': 3,\n",
       " 'fireemblem': 9,\n",
       " 'forgot': 1,\n",
       " 'post': 1,\n",
       " 'sothi': 3,\n",
       " 'regalia': 1,\n",
       " 'wish': 1,\n",
       " 'church': 2,\n",
       " 'peopl': 1,\n",
       " 'react': 1,\n",
       " 'fireemblemthre': 1,\n",
       " 'one': 4,\n",
       " 'titan': 4,\n",
       " 'daughter': 2,\n",
       " 'mytholog': 2,\n",
       " 'greekmytholog': 2,\n",
       " 'halloween': 2,\n",
       " 'feh': 4,\n",
       " 'witch': 1,\n",
       " 'kumkum': 4,\n",
       " 'bhagya': 4,\n",
       " 'spoiler': 2,\n",
       " 'alert': 1,\n",
       " 'prachi': 4,\n",
       " 'vow': 1,\n",
       " 'reveng': 1,\n",
       " 'follow': 4,\n",
       " 'us': 4,\n",
       " 'kumkumbhagya': 3,\n",
       " 'yoi': 1,\n",
       " '..': 4,\n",
       " 'henley': 1,\n",
       " 'wrenley': 1,\n",
       " 'meghan': 1,\n",
       " 'davina': 1,\n",
       " 'alexia': 1,\n",
       " 'adel': 1,\n",
       " 'jayda': 1,\n",
       " 'holland': 1,\n",
       " 'ashlyn': 1,\n",
       " 'capri': 1,\n",
       " 'anika': 1,\n",
       " 'reyna': 1,\n",
       " 'maleah': 1,\n",
       " 'final': 3,\n",
       " 'done': 1,\n",
       " 'vm': 2,\n",
       " 'ahaan-rhea-ishqi': 1,\n",
       " 'ft': 1,\n",
       " 'yaara': 1,\n",
       " 'paramsingh': 2,\n",
       " 'akshitamudg': 1,\n",
       " 'neharana': 1,\n",
       " 'ishqi': 1,\n",
       " 'ishqaan': 1,\n",
       " 'avm': 1,\n",
       " 'r': 1,\n",
       " 'dedic': 1,\n",
       " 'heartbeat': 1,\n",
       " 'parakshita': 1,\n",
       " 'ishkparzornahi': 1,\n",
       " 'ki': 1,\n",
       " 'famili': 3,\n",
       " 'miss': 1,\n",
       " 'alot': 1,\n",
       " 'fav': 1,\n",
       " 'big': 2,\n",
       " 'booti': 1,\n",
       " 'lizard': 1,\n",
       " 'pope': 1,\n",
       " 'fire': 2,\n",
       " 'emblem': 2,\n",
       " 'superexclus': 2,\n",
       " 'spoileralert': 2,\n",
       " \"rhea'\": 2,\n",
       " 'truth': 2,\n",
       " 'front': 2,\n",
       " '4saalbemisa': 1,\n",
       " 'chase': 1,\n",
       " 'two': 1,\n",
       " 'hungri': 1,\n",
       " 'protocyon': 1,\n",
       " 'brazilian': 1,\n",
       " 'cerrado': 1,\n",
       " 'commiss': 1,\n",
       " 'happi': 1,\n",
       " 'birthday': 1,\n",
       " 'teri': 1,\n",
       " 'hatcher': 1,\n",
       " 'terihatch': 1,\n",
       " 'loislan': 1,\n",
       " 'loisandclarkthenewadventuresofsuperman': 1,\n",
       " 'queenofdaxam': 1,\n",
       " 'btw': 2,\n",
       " 'cave': 2,\n",
       " 'wrote': 3,\n",
       " 'pine': 2,\n",
       " 'rheagard': 4,\n",
       " '<3': 2,\n",
       " '3': 2,\n",
       " 'edelgard': 3,\n",
       " 'seiro': 3,\n",
       " 'feel': 1,\n",
       " '->': 1,\n",
       " 'fire_emblem': 1,\n",
       " 'get': 3,\n",
       " 'loser': 1,\n",
       " 'flayn': 1,\n",
       " 'written': 3,\n",
       " 'updat': 3,\n",
       " 's01': 3,\n",
       " 'ep2015': 1,\n",
       " '8th': 1,\n",
       " 'decemb': 3,\n",
       " '2021': 3,\n",
       " 'daljeet': 1,\n",
       " 'support': 1,\n",
       " 'immacul': 1,\n",
       " 'archbishoprhea': 2,\n",
       " 'silli': 1,\n",
       " 'comic': 3,\n",
       " 'goe': 1,\n",
       " 'school': 1,\n",
       " 'pleas': 1,\n",
       " 'read': 1,\n",
       " 'left': 1,\n",
       " 'right': 4,\n",
       " 'top': 2,\n",
       " 'bottom': 1,\n",
       " 'manuelacasagranda': 1,\n",
       " 'hahaha': 1,\n",
       " 'macam': 1,\n",
       " 'tu': 1,\n",
       " 'lah': 2,\n",
       " 'summer': 1,\n",
       " 'banner': 1,\n",
       " 'vol': 1,\n",
       " 'preorder': 1,\n",
       " 'avaiabl': 1,\n",
       " 'etsi': 1,\n",
       " 'store': 1,\n",
       " 'sylvain': 1,\n",
       " 'felix': 1,\n",
       " 'ingrid': 1,\n",
       " 'ladi': 1,\n",
       " 'fanart': 2,\n",
       " 'wip': 2,\n",
       " 'jrpg': 1,\n",
       " 'list': 2,\n",
       " 'prompt': 1,\n",
       " 'come': 2,\n",
       " 'within': 1,\n",
       " 'next': 1,\n",
       " 'week': 1,\n",
       " 'meantim': 1,\n",
       " \"here'\": 1,\n",
       " 'tier': 1,\n",
       " \"mod'\": 1,\n",
       " '5': 1,\n",
       " 'cg': 1,\n",
       " 'new': 2,\n",
       " 'year': 1,\n",
       " 'draw': 3,\n",
       " 'manga': 1,\n",
       " 'mangaka': 1,\n",
       " 'anim': 1,\n",
       " 'animeart': 1,\n",
       " 'mangaart': 1,\n",
       " 'nintendo': 1,\n",
       " \"he'\": 1,\n",
       " 'gone': 1,\n",
       " 'mother': 1,\n",
       " 'definit': 1,\n",
       " 'problem': 1,\n",
       " 'threehous': 1,\n",
       " 'sing': 2,\n",
       " 'song': 2,\n",
       " 'someon': 1,\n",
       " 'littl': 1,\n",
       " 'preview': 1,\n",
       " 'piec': 2,\n",
       " 'beauti': 1,\n",
       " 'fireemblemhero': 1,\n",
       " 'rel': 1,\n",
       " 'quick': 1,\n",
       " 'fe': 1,\n",
       " 'illustr': 1,\n",
       " 'art': 2,\n",
       " 'gami': 1,\n",
       " 'io_ent': 1,\n",
       " 'girlgoroup': 1,\n",
       " 'jaeeun': 1,\n",
       " 'h': 2,\n",
       " \"darwin'\": 1,\n",
       " 'ep2014': 2,\n",
       " '7th': 2,\n",
       " 'fight': 2,\n",
       " 'abhi': 1,\n",
       " 'anjir': 1,\n",
       " 'itu': 1,\n",
       " 'siap': 1,\n",
       " 'langsung': 1,\n",
       " 'block': 1,\n",
       " 'tapi': 1,\n",
       " 'kalau': 1,\n",
       " 'join': 1,\n",
       " 'project': 1,\n",
       " 'gitu': 1,\n",
       " 'takut': 1,\n",
       " 'nggak': 3,\n",
       " 'kepegang': 1,\n",
       " 'gue': 1,\n",
       " 'jalanin': 1,\n",
       " 'sendiri': 1,\n",
       " 'aja': 1,\n",
       " 'wkwk': 1,\n",
       " 'banyak': 1,\n",
       " 'anak': 2,\n",
       " 'satu': 1,\n",
       " 'lagi': 1,\n",
       " 'nambah': 1,\n",
       " 'masa': 1,\n",
       " 'cuma': 1,\n",
       " 'dua': 1,\n",
       " 'kok': 1,\n",
       " 'seru': 1,\n",
       " 'emang': 1,\n",
       " 'pengen': 1,\n",
       " 'gabungin': 1,\n",
       " 'sama': 1,\n",
       " 'idol': 1,\n",
       " 'au': 1,\n",
       " 'x': 1,\n",
       " 'fantasi': 1,\n",
       " 'boleh': 1,\n",
       " 'ya': 1,\n",
       " 'realli': 1,\n",
       " 'love': 1,\n",
       " 'doglov': 1,\n",
       " 'letmetellyouaboutmybestfriend': 1,\n",
       " 'severu': 1,\n",
       " 'version': 1,\n",
       " 'made': 2,\n",
       " 'check': 1,\n",
       " 'still': 1,\n",
       " 'ukey': 2,\n",
       " '64': 1,\n",
       " 'vocal': 1,\n",
       " 'suppos': 1,\n",
       " 'panel': 2,\n",
       " 'realiz': 1,\n",
       " 'funni': 1,\n",
       " 'make': 2,\n",
       " 'fa': 1,\n",
       " 'best': 1,\n",
       " 'sambar': 1,\n",
       " 'recip': 1,\n",
       " 'chairman': 1,\n",
       " 'board': 1,\n",
       " 'lütfiyenel': 1,\n",
       " 'presid': 1,\n",
       " 'defenc': 1,\n",
       " 'industri': 1,\n",
       " 'cyber': 1,\n",
       " 'real': 1,\n",
       " 'worl': 1,\n",
       " 'hide': 1,\n",
       " 'natur': 1,\n",
       " 'wildlif': 1,\n",
       " 'entringen': 1,\n",
       " 'soni': 1,\n",
       " 'sonyalphaclub': 1,\n",
       " 'sonya': 1,\n",
       " '6000': 1,\n",
       " 'sonyalphasclub': 1,\n",
       " 'pixelandlen': 1,\n",
       " 'twspyexclus': 1,\n",
       " 'nayaaagaznayaandaaz': 1,\n",
       " 'tejo': 1,\n",
       " 'angad': 1,\n",
       " 'end': 1,\n",
       " 'major': 1,\n",
       " 'rift': 1,\n",
       " 'udaariyan': 1,\n",
       " 'mortuari': 1,\n",
       " 'suspici': 1,\n",
       " 'relationship': 1,\n",
       " 'sushant': 2,\n",
       " 'singh': 1,\n",
       " 'day': 2,\n",
       " 'death': 3,\n",
       " 'mumbai': 1,\n",
       " 'polic': 1,\n",
       " 'vickykatrinawed': 1,\n",
       " 'vicki': 1,\n",
       " 'friend': 1,\n",
       " 'meant': 1,\n",
       " \"i'm\": 2,\n",
       " 'finish': 1,\n",
       " 'face': 1,\n",
       " 'gotta': 1,\n",
       " 'adjust': 1,\n",
       " 'super': 1,\n",
       " 'proud': 1,\n",
       " 'far': 1,\n",
       " 'hope': 1,\n",
       " 'heart': 1,\n",
       " 'morn': 1,\n",
       " 'sunni': 1,\n",
       " 'rheafireemblem': 2,\n",
       " 'twitter': 1,\n",
       " 'happen': 1,\n",
       " '.\\n.\\n.': 1,\n",
       " 'edelg': 1,\n",
       " 'fancam': 1,\n",
       " 'deserv': 1,\n",
       " 'ladyrhea': 1,\n",
       " 'ferhea': 1,\n",
       " 'rheaf': 1,\n",
       " 'dishassrdoublemurd': 2,\n",
       " 'interconnect': 2,\n",
       " 'eye': 2,\n",
       " 'wit': 2,\n",
       " 'ne': 4,\n",
       " 'cbi': 2,\n",
       " 'ke': 8,\n",
       " 'saamn': 2,\n",
       " 'khole': 2,\n",
       " 'kai': 2,\n",
       " 'raaz': 2,\n",
       " 'pithani': 2,\n",
       " 'apna': 2,\n",
       " 'jurm': 2,\n",
       " 'kaboola': 1,\n",
       " 'bank': 2,\n",
       " 'mein': 2,\n",
       " 'rs': 2,\n",
       " '53': 2,\n",
       " 'karor': 4,\n",
       " 'uski': 2,\n",
       " 'baadab': 2,\n",
       " 'kewal': 2,\n",
       " '2': 2,\n",
       " 'hain': 2,\n",
       " 'paa': 2,\n",
       " 'k': 1,\n",
       " 'kabo': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a29dea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rhea', 50),\n",
       " ('fe3h', 16),\n",
       " ('...', 9),\n",
       " ('fireemblem', 9),\n",
       " ('ke', 8),\n",
       " ('fireemblemthreehous', 7),\n",
       " ('seteth', 5),\n",
       " ('sushantsinghrajput', 4),\n",
       " ('one', 4),\n",
       " ('titan', 4)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_sorted = list(freqs.items())\n",
    "freq_sorted.sort(key = lambda x : -x[1])\n",
    "freq_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "048b699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tweet, alphabet):\n",
    "    v = np.zeros(len(alphabet))\n",
    "    for i in range(len(alphabet)):\n",
    "        if alphabet[i] in tweet:\n",
    "            v[i] += 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c5a657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closestCluster(vector, centroids):\n",
    "    closest = -1\n",
    "    minDist = 2**30\n",
    "    for key in centroids:\n",
    "        dist = np.linalg.norm(centroids[key] - vector)\n",
    "        if dist < minDist:\n",
    "            minDist = dist\n",
    "            closest = key\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc117ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignToCluster(clusters, vectors, centroids):\n",
    "    for i in range(len(vectors)):\n",
    "        c = closestCluster(vectors[i], centroids)\n",
    "        clusters[c].append(i)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a038a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(k, max_iter, vectors):\n",
    "    clusters = {}\n",
    "    centroids = {}\n",
    "    idx = np.random.choice(len(vectors), k, replace=False)\n",
    "    for i in range(k):\n",
    "        clusters[i] = []\n",
    "        centroids[i] = vectors[idx[i]] \n",
    "    clusters = assignToCluster(clusters, vectors, centroids)\n",
    "    for _ in range(max_iter-1):\n",
    "        for i in range(k):\n",
    "            for j in clusters[i]:\n",
    "                centroids[i] = centroids[i] + vectors[j]\n",
    "            if clusters[i] != []:\n",
    "                centroids[i] = centroids[i] / len(clusters[i])\n",
    "            if len(clusters[i]):\n",
    "                clusters[i].clear()\n",
    "        clusters = assignToCluster(clusters, vectors, centroids)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07b0974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = [i[0] for i in freq_sorted]\n",
    "clusters = dict()\n",
    "vectors = dict()\n",
    "for i in range(len(processed_tweets)):\n",
    "    vectors[i] = vectorize(processed_tweets[i], alphabet)\n",
    "clusters[0] = [i for i in range(len(processed_tweets))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38018877",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = kmeans(20, 100, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ed52ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  13,\n",
       "  14,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  25,\n",
       "  27,\n",
       "  31,\n",
       "  32,\n",
       "  34,\n",
       "  37,\n",
       "  39,\n",
       "  40,\n",
       "  48,\n",
       "  50,\n",
       "  54,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  63,\n",
       "  64],\n",
       " 1: [],\n",
       " 2: [],\n",
       " 3: [],\n",
       " 4: [],\n",
       " 5: [],\n",
       " 6: [],\n",
       " 7: [62, 65],\n",
       " 8: [16, 33, 35, 38],\n",
       " 9: [],\n",
       " 10: [],\n",
       " 11: [],\n",
       " 12: [],\n",
       " 13: [],\n",
       " 14: [],\n",
       " 15: [],\n",
       " 16: [],\n",
       " 17: [7,\n",
       "  12,\n",
       "  15,\n",
       "  17,\n",
       "  24,\n",
       "  26,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  36,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  49,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  55],\n",
       " 18: [],\n",
       " 19: []}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d202d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4765e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
